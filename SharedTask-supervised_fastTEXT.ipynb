{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_json (r'/home/areej/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/dataset/train.json')\n",
    "#print (df.head(5))\n",
    "dev_df = pd.read_json (r'/home/areej/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/dataset/dev.json')\n",
    "#print (df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n"
     ]
    }
   ],
   "source": [
    "CNN_df=pd.DataFrame()\n",
    "for index,row in train_df.iterrows():\n",
    "    if row['tokens'][row['acronym']]=='ART':\n",
    "        CNN_df=CNN_df.append(row)\n",
    "\n",
    "        \n",
    "print(CNN_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from multiprocessing import Process, current_process\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'summary', ',', 'it', 'is', 'evident', 'that', 'their', 'complexities', 'are', 'in', 'increasing', 'order', ':', 'leakage', '-', 'based', ',', 'Max', '-', 'SR', ',', 'and', 'generalized', 'EDAS', '.']\n",
      "['In', 'summary', ',', 'it', 'is', 'evident', 'that', 'their', 'complexities', 'are', 'in', 'increasing', 'order', ':', 'leakage', '-', 'based', ',', 'Max', '-']\n",
      "[',', 'and', 'generalized', 'EDAS', '.']\n",
      "SR\n"
     ]
    }
   ],
   "source": [
    "#get both side for acronymn\n",
    "\n",
    "term=train_df['tokens'][0]\n",
    "left_side=term[0:int(train_df['acronym'][0])]\n",
    "right_side=term[int(train_df['acronym'][0])+1:]\n",
    "print(term)\n",
    "\n",
    "print(term[0:int(train_df['acronym'][0])])\n",
    "print(term[int(train_df['acronym'][0])+1:])\n",
    "print(term[train_df['acronym'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_special(wordSpecial):\n",
    "    t= False\n",
    "    if (bool(re.search('^[a-zA-Z0-9]*$',wordSpecial))==True) and wordSpecial.isdigit()==False:\n",
    "        t=True\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american diabetes association 's\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('/home/ArMuas/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/dataset/diction.json') as file:\n",
    "    diction = json.load(file)\n",
    "    \n",
    "#sense vetor generation\n",
    "'''\n",
    "for acr, lfs in diction.items():\n",
    "        for lf in lfs:\n",
    "            print(acr,lf)\n",
    "            print(get_max_embedding(lf))\n",
    "            #freq[lf]=get_max_embedding(lf)\n",
    "'''\n",
    "print(diction['ADA'])          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_max_embedding(sense):\n",
    "    emb_vector=np.zeros(300)\n",
    "    for word in sense:\n",
    "        if check_special(word)==True:\n",
    "            embedding_vector = np.nan_to_num(model[word.lower()])\n",
    "            if embedding_vector is not None:\n",
    "                emb_vector = np.maximum(emb_vector,embedding_vector)\n",
    "    \n",
    "    return emb_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(feature_list,sense):\n",
    "    v = DictVectorizer(sparse=None)\n",
    "    X=feature_list\n",
    "    #X = v.fit_transform(feature_list)\n",
    "    Encoder = LabelEncoder()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, sense, test_size = 0.2, random_state=0)\n",
    "    Train_Y = Encoder.fit_transform(y_train)\n",
    "    Test_Y = Encoder.fit_transform(y_test)\n",
    "    #print(len(X_train ),len(y_train))\n",
    "    return X_train, X_test, Train_Y, Test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areej/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB 100.0\n",
      "SVM 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n            \\n    pred['prediction'] = pred_sense\\n    predictions.append(pred)        \\n    #print(d['id'],d['expansion'],max_,pred )\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "#models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "#models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "#models.append(('CART', DecisionTreeClassifier(random_state=0)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto' )))\n",
    "with open('/home/areej/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/dataset/diction.json') as file:\n",
    "    diction = json.load(file)\n",
    "    \n",
    "with open('/home/areej/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/dataset/train.json') as file:\n",
    "    data = json.load(file)\n",
    "embedding_matrix = np.zeros((1, 300)) #initalize embedding matrix\n",
    "'''\n",
    "predictions = []\n",
    "for d in data:\n",
    "    pred = {\n",
    "        'id': d['id'],\n",
    "        'prediction': ''}\n",
    "    \n",
    "    candids = diction[d['tokens'][d['acronym']]]\n",
    "    \n",
    "    #sense embedding\n",
    "    sens_emd_dic={}\n",
    "    for sense in candids:\n",
    "        sens_emd_dic[sense]=get_max_embedding(sense.split())\n",
    "'''\n",
    "for index,row in CNN_df.iterrows():\n",
    "        \n",
    "    #context embedding for each senstence\n",
    "       \n",
    "    if row['acronym'] != 0:        \n",
    "        left_side=row['tokens'][0:int(row['acronym'])]\n",
    "    else:\n",
    "        left_side=[]\n",
    "    \n",
    "    right_side=row['tokens'][int(row['acronym'])+1:]\n",
    "    \n",
    "    context_vec=(np.nan_to_num(get_max_embedding(right_side))\n",
    "                                +\n",
    "                                np.nan_to_num(get_max_embedding(left_side))/2)\n",
    "    embedding_matrix = np.vstack([embedding_matrix, context_vec]) #add vector features\n",
    "\n",
    "x = np.delete(embedding_matrix, (0), axis=0) #delete first row\n",
    "\n",
    "senses=CNN_df['expansion']\n",
    "\n",
    "X_train, X_test, Train_Y, Test_Y= train_test_data(x,senses)\n",
    "    \n",
    "    \n",
    "for name, mod in models:\n",
    "    mod.fit(X_train,Train_Y)\n",
    "    prediction=mod.predict(X_test)\n",
    "    print(name,metrics.accuracy_score(Test_Y,prediction)*100)\n",
    "    \n",
    "'''\n",
    "            \n",
    "    pred['prediction'] = pred_sense\n",
    "    predictions.append(pred)        \n",
    "    #print(d['id'],d['expansion'],max_,pred )\n",
    "'''\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1a22996d393b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#labels = [classes[i] for i in labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEncoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictions_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classes_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "#mod.classes_\n",
    "#labels = np.argmax(Test_Y, axis=1)\n",
    "classes = mod.classes_\n",
    "#labels = [classes[i] for i in labels]\n",
    "Encoder = LabelEncoder()\n",
    "predictions_test = Encoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_train_cosine_FastText_MAX.json', 'w') as file:\n",
    "    json.dump(predictions, file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8021916]]\n"
     ]
    }
   ],
   "source": [
    "print(np.maximum(cosine_similarity(context_vec,sen1_vec),cosine_similarity(context_vec,sen2_vec),cosine_similarity(context_vec,sen3_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areej/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#import gensim\n",
    "#import FastText as ft\n",
    "model=FT_gensim.load_fasttext_format(\"/home/areej/anaconda3/AAAI-21-SDU-shared-task-2-AD-master/pretrained/wiki.en/wiki.en.bin\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/areej/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.99643850e-01,  8.51161256e-02, -5.51894903e-02,  1.31416783e-01,\n",
       "       -3.42630148e-02,  1.16869882e-01,  2.42972206e-02, -3.65913302e-01,\n",
       "       -1.60213172e-01,  1.30407602e-01, -5.11050969e-02, -1.94264352e-01,\n",
       "        1.28881589e-01, -1.31380439e-01,  5.16473390e-02,  2.11300626e-02,\n",
       "       -1.49447724e-01,  1.17996462e-01,  2.64452636e-01,  2.15311825e-01,\n",
       "        5.97878359e-02,  1.45647615e-01, -1.35129586e-01, -8.24247524e-02,\n",
       "       -3.03584695e-01,  1.36005461e-01, -1.56227082e-01,  7.74830207e-02,\n",
       "        2.24251732e-01,  2.29710922e-01, -1.45234153e-01,  2.06172764e-01,\n",
       "       -1.90676510e-01,  1.39753044e-01, -6.74275681e-02, -3.99615355e-02,\n",
       "       -1.16826892e-02, -2.96144206e-02, -1.90305188e-01, -1.75481573e-01,\n",
       "       -2.66916398e-02, -1.05777696e-01, -1.13316916e-01,  1.38660282e-01,\n",
       "       -4.11015116e-02,  1.27849042e-01,  8.43051895e-02, -1.61175996e-01,\n",
       "        2.20806375e-02, -3.68535183e-02, -5.00785224e-02, -3.79848480e-02,\n",
       "        6.92265555e-02, -1.06075242e-01, -3.60440165e-02,  2.89170712e-01,\n",
       "        3.95584218e-02,  9.63258669e-02,  1.44658253e-01, -1.34337163e-02,\n",
       "       -9.12635624e-02, -4.02292237e-02,  3.52939934e-01, -3.34889561e-01,\n",
       "        1.06155150e-01, -3.55229735e-01, -7.79318735e-02, -5.06630819e-03,\n",
       "       -7.95429423e-02,  1.18139789e-01, -1.34915039e-01, -4.81506586e-02,\n",
       "        1.31968588e-01, -2.69174755e-01, -1.82658017e-01,  5.24198152e-02,\n",
       "        1.47712573e-01,  2.52091289e-01, -9.09661949e-02,  6.29377067e-02,\n",
       "       -1.53107896e-01,  1.84721291e-01,  4.40060645e-02,  3.84389423e-02,\n",
       "        5.96599430e-02, -2.02554479e-01,  2.62218416e-02,  2.44880486e-02,\n",
       "       -1.68582797e-02, -2.75491923e-01,  1.03340797e-01,  1.03431173e-01,\n",
       "        4.44637895e-01, -2.07551539e-01,  2.24496182e-02, -7.24508762e-02,\n",
       "        1.03905432e-01,  1.32439464e-01,  7.91968927e-02, -3.73598654e-03,\n",
       "       -9.65082422e-02,  3.51292938e-02, -1.18030636e-02,  7.47407526e-02,\n",
       "       -1.16414361e-01, -6.42348430e-04, -1.58587471e-01,  1.23144276e-01,\n",
       "       -6.24083988e-02,  1.07500084e-01, -5.19954525e-02,  7.96828941e-02,\n",
       "       -6.11272454e-02,  2.67418623e-02, -1.18368559e-01, -7.48767778e-02,\n",
       "        5.74037671e-01,  6.63794205e-02, -5.34666814e-02,  1.29762620e-01,\n",
       "        1.21906228e-01, -6.57488033e-02, -1.04514696e-01,  3.80976945e-01,\n",
       "        8.55494514e-02,  1.85029119e-01,  4.40961123e-02,  5.60126640e-03,\n",
       "       -5.52415848e-04,  2.95631677e-01,  2.68963594e-02,  1.56840742e-01,\n",
       "        1.22143202e-01,  1.05384991e-01,  6.90675676e-02,  2.12185845e-01,\n",
       "        3.23336944e-02, -1.00326240e-02,  7.73404539e-02,  1.26911029e-01,\n",
       "       -1.04547525e-02,  5.79881221e-02,  1.72356665e-01, -9.18606818e-02,\n",
       "        3.94569635e-02,  2.05765199e-02, -2.82884464e-02,  1.53322443e-01,\n",
       "       -8.32294300e-02,  1.18506931e-01,  6.08213693e-02,  1.32230222e-01,\n",
       "        1.46141216e-01, -2.85595119e-01, -1.41107384e-02, -2.35647634e-01,\n",
       "        2.79031545e-01,  3.26521136e-02,  1.79676786e-02,  1.82317391e-01,\n",
       "       -1.24641865e-01,  1.23216942e-01, -1.89783916e-01,  3.03012244e-02,\n",
       "        9.06858370e-02,  8.47804546e-02, -6.30223677e-02, -1.25340953e-01,\n",
       "        1.51416406e-01, -1.55431712e-02, -3.61054391e-01, -1.98009878e-01,\n",
       "       -2.12593898e-01, -1.89335823e-01,  3.39453444e-02, -1.38254344e-01,\n",
       "       -3.97766680e-02,  5.72146736e-02, -2.89799627e-02, -2.15030417e-01,\n",
       "        8.17454979e-02, -6.42327145e-02,  1.11487389e-01,  3.93949479e-01,\n",
       "       -5.67515343e-02,  2.39753723e-01,  1.78479940e-01, -1.65832102e-01,\n",
       "        1.15679309e-01, -4.70795296e-02, -1.37933314e-01, -1.59355581e-01,\n",
       "        2.77854830e-01,  1.81923956e-01, -8.96597579e-02, -1.70537114e-01,\n",
       "        2.40015499e-02,  1.01110488e-01, -3.39975268e-01, -4.06966768e-02,\n",
       "        1.73763499e-01,  1.58598199e-01,  1.02840073e-01,  2.91670829e-01,\n",
       "        6.27476946e-02, -1.57532394e-01, -1.69143334e-01,  2.05021337e-01,\n",
       "       -1.08353645e-01, -3.55564244e-02,  2.18031630e-01, -6.89723194e-02,\n",
       "        1.01761647e-01,  5.47267077e-03,  3.30233395e-01, -2.04258576e-01,\n",
       "        2.43877664e-01, -1.50763988e-02, -1.52426019e-01,  1.47848800e-01,\n",
       "       -1.15902975e-01, -1.53342411e-01,  1.95329487e-01, -1.09034151e-01,\n",
       "        1.89673245e-01,  3.82439755e-02, -1.11862309e-02, -6.12076521e-02,\n",
       "       -1.92593392e-02, -6.54186448e-03,  3.08633596e-01,  9.39603746e-02,\n",
       "       -1.54413626e-01,  9.03788432e-02, -6.91621453e-02,  3.79421972e-02,\n",
       "        2.91717231e-01, -3.56379002e-02,  5.03260866e-02, -2.61056066e-01,\n",
       "        1.87629998e-01,  8.42093751e-02,  1.50925696e-01,  3.36661935e-04,\n",
       "       -9.02480260e-02,  1.56474963e-01,  2.74207354e-01,  2.87151843e-01,\n",
       "        1.75024979e-04, -3.95013876e-02,  7.16312677e-02,  1.14741199e-01,\n",
       "       -1.57517195e-01, -4.62490804e-02, -1.44111097e-01, -2.07851127e-01,\n",
       "       -1.20202586e-01, -2.98922151e-01, -7.16952011e-02, -1.26211390e-01,\n",
       "        5.42803444e-02,  2.20629647e-01, -3.80581647e-01,  5.63277863e-02,\n",
       "        8.66703093e-02,  5.43098338e-02, -4.43585180e-02, -6.60502464e-02,\n",
       "       -2.13774905e-01, -2.22552195e-01, -1.69780806e-01, -1.09232135e-01,\n",
       "        2.50118613e-01, -2.53560431e-02,  3.47115993e-02, -3.04063827e-01,\n",
       "       -1.54464960e-01,  1.30732171e-02, -1.65839881e-01, -1.77344710e-01,\n",
       "       -9.04255584e-02,  1.75014846e-02,  3.97020578e-02, -2.70641446e-01,\n",
       "        2.79282838e-01, -1.28156513e-01,  2.47323513e-02,  3.25664937e-01,\n",
       "       -5.41122817e-02,  3.59219648e-02,  1.86359994e-02, -2.48732477e-01,\n",
       "       -7.21943155e-02, -9.18415785e-02, -3.47280949e-02, -1.19939044e-01,\n",
       "       -3.69522423e-02,  3.71205777e-01,  3.82915884e-02,  1.34257883e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
